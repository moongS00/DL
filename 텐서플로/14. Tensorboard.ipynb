{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90778585",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "- TensorFlow에서 제공하는 시각화 툴\n",
    "- 학습하는 중간의 그래프나 여러가지 정보를 Web UI로 조회 가능\n",
    "- 학습 log를 시각화 하는 것이라고 보면 됨\n",
    "\n",
    "https://www.tensorflow.org/tensorboard?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a01213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Add\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(7777)\n",
    "tf.random.set_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e2f25d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) float32\n",
      "(50000, 10) float32\n",
      "(10000, 32, 32, 3) float32\n",
      "(10000, 10) float32\n"
     ]
    }
   ],
   "source": [
    "class Cifar10DataLoader():\n",
    "    def __init__(self):\n",
    "        # data load\n",
    "        (self.train_x, self.train_y), \\\n",
    "            (self.test_x, self.test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "        self.input_shape = self.train_x.shape[1:]\n",
    "\n",
    "    def scale(self, x):\n",
    "\n",
    "        return (x / 255.0).astype(np.float32)\n",
    "\n",
    "    def preprocess_dataset(self, dataset):\n",
    "\n",
    "        (feature, target) = dataset\n",
    "\n",
    "        # scaling #\n",
    "        scaled_x = np.array([self.scale(x) for x in feature])\n",
    "\n",
    "        # label encoding #\n",
    "        ohe_y = np.array([tf.keras.utils.to_categorical(\n",
    "            y, num_classes=10) for y in target])\n",
    "        \n",
    "        return scaled_x, ohe_y.squeeze(1)\n",
    "\n",
    "    def get_train_dataset(self):\n",
    "        return self.preprocess_dataset((self.train_x, self.train_y))\n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        return self.preprocess_dataset((self.test_x, self.test_y))\n",
    "\n",
    "cifar10_loader = Cifar10DataLoader()\n",
    "train_x, train_y = cifar10_loader.get_train_dataset()\n",
    "\n",
    "print(train_x.shape, train_x.dtype)\n",
    "print(train_y.shape, train_y.dtype)\n",
    "\n",
    "test_x, test_y = cifar10_loader.get_test_dataset()\n",
    "\n",
    "print(test_x.shape, test_x.dtype)\n",
    "print(test_y.shape, test_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e36673f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 8, 8, 16)     0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 32)     544         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 32)     9248        ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 32)     544         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 32)     1056        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 32)     0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 32)     1056        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 32)     9248        ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 32)     1056        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 8, 8, 32)     0           ['add[0][0]',                    \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 32)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           5130        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,330\n",
      "Trainable params: 28,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_resnet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    net = Conv2D(16, kernel_size=3, strides=2,\n",
    "                 padding='same', activation='relu')(inputs)\n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net1_1 = Conv2D(32, kernel_size=1, padding='same')(net)\n",
    "    net = Add()([net1_1, net3])\n",
    "    \n",
    "    net1 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net)\n",
    "    net2 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(net1)\n",
    "    net3 = Conv2D(32, kernel_size=1, padding='same', activation='relu')(net2)\n",
    "    \n",
    "    net = Add()([net, net3])\n",
    "    \n",
    "    net = MaxPool2D()(net)\n",
    "    \n",
    "    net = Flatten()(net)\n",
    "    net = Dense(10, activation=\"softmax\")(net)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=net, name='resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_resnet((32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30212488",
   "metadata": {},
   "source": [
    "## (1) fit 함수로 학습 => callback 함수 사용! \n",
    "- TensorBoard 가 시각화할 때 사용할 log를 callback 함수로 작성\n",
    "- log_dir 을 계획적으로 정리해서 log들을 잘 저장하는 것이 중요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c387eae",
   "metadata": {},
   "source": [
    "#### callback 함수 설정\n",
    "- 파일명을 사용하는 logs/모델명/만든시간 으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53705aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/fit/20221201-214007'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "cur_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "lod_dir = \"logs/fit/\" + cur_time\n",
    "lod_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42769e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=lod_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4918b",
   "metadata": {},
   "source": [
    "#### lr, loss, opt 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d631833",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b1323",
   "metadata": {},
   "source": [
    "#### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d77cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 28s 17ms/step - loss: 2.3439 - accuracy: 0.1005 - val_loss: 2.3302 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 2.3357 - accuracy: 0.1029 - val_loss: 2.3209 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 2.3409 - accuracy: 0.0978 - val_loss: 2.3737 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 2.3401 - accuracy: 0.0987 - val_loss: 2.3292 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 30s 19ms/step - loss: 2.3431 - accuracy: 0.0994 - val_loss: 2.3364 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251ce0dd3f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, \n",
    "          y=train_y, \n",
    "          epochs=5,\n",
    "          validation_data=(test_x, test_y), \n",
    "          callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee49867",
   "metadata": {},
   "source": [
    "#### TensorBoard  실행\n",
    "- 원래는 터미널에서 실행\n",
    "- 외부 서버에서 주피터에 접속한 경우 맨 뒤에  `--bind_all` 를 붙여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8eb72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8819c2",
   "metadata": {},
   "source": [
    "## (2) 내가 만든 함수로 학습 => tf.summary 사용! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d4386",
   "metadata": {},
   "source": [
    "#### 함수 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ce773e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y) :\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(y, pred)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y) :\n",
    "    \n",
    "    pred = model(x)\n",
    "    loss = loss_fn(y, pred)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e8ec8",
   "metadata": {},
   "source": [
    "#### 로그 저장 경로 설정\n",
    "- callback 함수는 train, test 파일을 자동으로 따로 저장해주지만\n",
    "- 이번 경우에는 내가 수동으로 따로 저장해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5def9d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_dir = \"logs/gradtape/train/\" + cur_time\n",
    "test_log_dir = \"logs/gradtape/test/\" + cur_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ba439",
   "metadata": {},
   "source": [
    "#### tf.summary 사용\n",
    "- 인자로 파일 저장위치를 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bdf56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c235d93",
   "metadata": {},
   "source": [
    "#### 학습\n",
    "- 매 epoch 마다 log를 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff93dcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 2.355724573135376, accuracy: 0.09937179833650589, test_loss: 2.3273210525512695, test_acc: 0.09995993226766586\n",
      "epoch 2 loss: 2.320366621017456, accuracy: 0.0985715463757515, test_loss: 2.307554006576538, test_acc: 0.09985977411270142\n",
      "epoch 3 loss: 2.3251609802246094, accuracy: 0.09889164566993713, test_loss: 2.3238322734832764, test_acc: 0.09985977411270142\n",
      "epoch 4 loss: 2.3269894123077393, accuracy: 0.0997319146990776, test_loss: 2.3113343715667725, test_acc: 0.09985977411270142\n",
      "epoch 5 loss: 2.326922655105591, accuracy: 0.0988716408610344, test_loss: 2.318948268890381, test_acc: 0.10016025602817535\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "num_of_batch_train = train_x.shape[0] // batch_size\n",
    "num_of_batch_test = test_x.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    for i in range(num_of_batch_train):\n",
    "        idx = i * batch_size\n",
    "        x, y = train_x[idx:idx+batch_size], train_y[idx:idx+batch_size]\n",
    "        train_step(x, y)\n",
    "        print(\"\\r Train : {} / {}\".format(i, num_of_batch_train), end='\\r')\n",
    "\n",
    "        \n",
    "    for i in range(num_of_batch_test):\n",
    "        idx = i * batch_size\n",
    "        x, y = test_x[idx:idx+batch_size], test_y[idx:idx+batch_size]\n",
    "        test_step(x, y)\n",
    "        print(\"\\r Test : {} / {}\".format(i, num_of_batch_test), end='\\r')\n",
    "        \n",
    "    # log 기록(loss, acc는 scalar라서 tf.summary.scalar 안에 들어있다)    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('acc', train_accuracy.result(), step=epoch)\n",
    "        \n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('acc', test_accuracy.result(), step=epoch)\n",
    "        \n",
    "    fmt = 'epoch {} loss: {}, accuracy: {}, test_loss: {}, test_acc: {}'\n",
    "    print(fmt.format(epoch+1, \n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result(),\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()\n",
    "                    ))\n",
    "    \n",
    "    # 매 epoch 마다 loss, acc 값 reset\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "249c6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde8226",
   "metadata": {},
   "source": [
    "## (3) Tensorboard에 이미지 데이터 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a1010b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = train_x[777]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1827e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/train_data/20221201-214007'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = \"logs/train_data/\" + cur_time\n",
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8ec3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "for i in np.random.randint(10000, size=10):    \n",
    "    img = train_x[i:i+1]  # 사진 파일의 차우너을 줄이지 않기 위한 slicing \n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Training Sample data : {}\".format(i), img, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63e57198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be100f4",
   "metadata": {},
   "source": [
    "## (4) LambdaCallback을 사용하여 Tensorboard에 Confusion Matrix 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44062436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    threshold = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure\n",
    "\n",
    "logdir = \"logs/fit/cm/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "test_images = test_x[:100]\n",
    "test_labels = np.argmax(test_y[:100], axis=1)\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    test_pred_raw = model.predict(test_images)\n",
    "    test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "    \n",
    "    classes = np.arange(10)\n",
    "    cm = confusion_matrix(test_labels, test_pred, labels=classes)\n",
    "    \n",
    "    figure = plot_confusion_matrix(cm, class_names=classes)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1e2c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "845a568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 0s 6ms/step0s - loss: 2.3066 - accuracy: 0.10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 2.3066 - accuracy: 0.1001 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 5ms/step0s - loss: 2.3054 - accuracy: 0.10\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 2.3054 - accuracy: 0.1027 - val_loss: 2.3066 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 8ms/step0s - loss: 2.3044 - accuracy: 0.09\n",
      "1563/1563 [==============================] - 43s 27ms/step - loss: 2.3044 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 4ms/step0s - loss: 2.3051 - accuracy: 0.09\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 2.3052 - accuracy: 0.0999 - val_loss: 2.3071 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 4ms/step0s - loss: 2.3192 - accuracy: 0.09\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 2.3192 - accuracy: 0.0989 - val_loss: 2.3613 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251d0e0c340>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x, \n",
    "          y=train_y,\n",
    "          epochs=5,\n",
    "          batch_size=32,\n",
    "          validation_data=(test_x, test_y),\n",
    "          callbacks=[tb_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06604e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
